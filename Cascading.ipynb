{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ihIttWCR1gxC","executionInfo":{"status":"ok","timestamp":1733071326488,"user_tz":-330,"elapsed":24433,"user":{"displayName":"Damanjit Singh","userId":"08687351702135121050"}},"outputId":"e08de386-43cc-4166-9401-45cc1b7acbe2"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"VQMZVijx1mRk","executionInfo":{"status":"ok","timestamp":1733071331237,"user_tz":-330,"elapsed":4794,"user":{"displayName":"Damanjit Singh","userId":"08687351702135121050"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3a01aa13-92d7-4757-cfcd-cb5ad2073175"},"outputs":[{"output_type":"stream","name":"stdout","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100  3999    0  3999    0     0   5771      0 --:--:-- --:--:-- --:--:--  5770\n","100  517k  100  517k    0     0   298k      0  0:00:01  0:00:01 --:--:-- 1217k\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100  4063    0  4063    0     0   7116      0 --:--:-- --:--:-- --:--:--  7115\n","100  392k  100  392k    0     0   384k      0  0:00:01  0:00:01 --:--:--  384k\n"]}],"source":["url = 'https://anaconda.org/conda-forge/libta-lib/0.4.0/download/linux-64/libta-lib-0.4.0-h166bdaf_1.tar.bz2'\n","!curl -L $url | tar xj -C /usr/lib/x86_64-linux-gnu/ lib --strip-components=1\n","url = 'https://anaconda.org/conda-forge/ta-lib/0.4.19/download/linux-64/ta-lib-0.4.19-py310hde88566_4.tar.bz2'\n","!curl -L $url | tar xj -C /usr/local/lib/python3.10/dist-packages/ lib/python3.10/site-packages/talib --strip-components=3\n","import talib"]},{"cell_type":"code","source":["!pip install TA-Lib yfinance pandas scikit-learn matplotlib"],"metadata":{"id":"INTwn_rg1nj3","executionInfo":{"status":"ok","timestamp":1733071360851,"user_tz":-330,"elapsed":29624,"user":{"displayName":"Damanjit Singh","userId":"08687351702135121050"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"fac702b7-6338-4894-fe43-5122c46a05d9"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting TA-Lib\n","  Downloading TA-Lib-0.5.1.tar.gz (369 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m369.6/369.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: yfinance in /usr/local/lib/python3.10/dist-packages (0.2.49)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from TA-Lib) (1.26.4)\n","Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.32.3)\n","Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance) (0.0.11)\n","Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (5.3.0)\n","Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.3.6)\n","Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2024.2)\n","Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.4.6)\n","Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.10/dist-packages (from yfinance) (3.17.8)\n","Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.12.3)\n","Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (1.16.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2024.8.30)\n","Building wheels for collected packages: TA-Lib\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for TA-Lib \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Building wheel for TA-Lib (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n","\u001b[31m  ERROR: Failed building wheel for TA-Lib\u001b[0m\u001b[31m\n","\u001b[0mFailed to build TA-Lib\n","\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (TA-Lib)\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["\n","import numpy as np\n","import pandas as pd\n","import yfinance as yf\n","import talib as ta\n","import matplotlib.pyplot as plt\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import accuracy_score\n","from datetime import datetime, timedelta\n","\n","# Function to fetch stock market data\n","def fetch_stock_data(ticker, start_date, end_date, interval='5m'):\n","    try:\n","        data = yf.download(ticker, start=start_date, end=end_date, interval=interval)\n","        if data.empty:\n","            print(f\"No data found for {ticker} during the specified date range.\")\n","            return pd.DataFrame()\n","        return data\n","    except Exception as e:\n","        print(f\"Error fetching data for {ticker}: {e}\")\n","        return pd.DataFrame()\n","\n","# Add technical indicators\n","def add_technical_indicators(df):\n","    if 'Close' not in df.columns:\n","        raise ValueError(\"Error: 'Close' column not found in DataFrame!\")\n","    close_prices = df['Close'].values.flatten()\n","    df['MA5'] = ta.SMA(close_prices, timeperiod=5)\n","    df['MA20'] = ta.SMA(close_prices, timeperiod=20)\n","    df['RSI'] = ta.RSI(close_prices, timeperiod=14)\n","    upper, middle, lower = ta.BBANDS(close_prices, timeperiod=20, nbdevup=2, nbdevdn=2, matype=0)\n","    df['BB_upper'] = upper\n","    df['BB_lower'] = lower\n","    macd, macdsignal, macdhist = ta.MACD(close_prices, fastperiod=12, slowperiod=26, signalperiod=9)\n","    df['MACD'] = macd\n","    df['MACD_signal'] = macdsignal\n","    return df.dropna()\n","\n","# Generate targets\n","def generate_target(df, n_periods=10):\n","    df['Target'] = np.where(df['Close'].shift(-n_periods) > df['Close'], 1, 0)\n","    return df.dropna()\n","\n","# Prepare data for training\n","def prepare_data(df):\n","    features = ['MA5', 'MA20', 'RSI', 'BB_upper', 'BB_lower', 'MACD', 'MACD_signal']\n","    X = df[features].values\n","    y = df['Target'].values\n","    return X, y\n","\n","# Train cascade model\n","def train_cascade(X_train, y_train, num_models=3):\n","    models = []\n","    for i in range(num_models):\n","        model = MLPClassifier(hidden_layer_sizes=(10,), solver='adam', alpha=0.0001, max_iter=100000 )\n","        model.fit(X_train, y_train)\n","        models.append(model)\n","    return models\n","\n","# Cascading prediction\n","def cascading_predict(models, X, y, max_impurity=0.002):\n","    unpruned = []\n","    level_accuracies = []\n","    correct_counts = []\n","    incorrect_counts = []\n","\n","    for model in models:\n","        probs = model.predict_proba(X)\n","        correct_predictions = 0\n","        incorrect_predictions = 0\n","        total_predictions = 0\n","        next_X, next_y = [], []\n","        for idx, prob in enumerate(probs):\n","            gini = 1 - np.sum(prob ** 2)\n","            if gini <= max_impurity:\n","                if np.argmax(prob) == y[idx]:\n","                    correct_predictions += 1\n","                else:\n","                    incorrect_predictions += 1\n","                total_predictions += 1\n","                unpruned.append((prob, X[idx], y[idx]))\n","            else:\n","                next_X.append(X[idx])\n","                next_y.append(y[idx])\n","        level_accuracy = correct_predictions / total_predictions if total_predictions else 0\n","        level_accuracies.append(level_accuracy)\n","        correct_counts.append(correct_predictions)\n","        incorrect_counts.append(incorrect_predictions)\n","        X, y = np.array(next_X), np.array(next_y)\n","\n","    return unpruned, level_accuracies, correct_counts, incorrect_counts\n","\n","# Synthetic data generation\n","def generate_synthetic_data(size=1000):\n","    np.random.seed(42)\n","    X = np.random.rand(size, 7)\n","    y = (np.sum(X, axis=1) > 3.5).astype(int)\n","    return X, y\n","\n","# Function to plot level-wise performance\n","def plot_level_performance(level_accuracies, correct_counts, incorrect_counts, title=\"Cascade Level Performance\"):\n","    levels = range(1, len(level_accuracies) + 1)\n","    fig, ax1 = plt.subplots(figsize=(10, 6))\n","\n","    # Bar chart for correct and incorrect counts\n","    ax1.bar(levels, correct_counts, label=\"Correct Predictions\", color='green', alpha=0.7)\n","    ax1.bar(levels, incorrect_counts, label=\"Incorrect Predictions\", color='red', alpha=0.7, bottom=correct_counts)\n","    ax1.set_ylabel(\"Number of Predictions\")\n","    ax1.set_xlabel(\"Cascade Level\")\n","    ax1.set_title(title)\n","    ax1.legend(loc=\"upper left\")\n","\n","    # Line graph for accuracy\n","    ax2 = ax1.twinx()\n","    ax2.plot(levels, level_accuracies, label=\"Accuracy\", color='blue', marker='o', linestyle='--')\n","    ax2.set_ylabel(\"Accuracy\")\n","    ax2.set_ylim(0, 1)\n","    ax2.legend(loc=\"upper right\")\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","# Main execution\n","ticker = \"RELIANCE.NS\"\n","end_date = datetime.today().strftime('%Y-%m-%d')\n","start_date = (datetime.today() - timedelta(days=30)).strftime('%Y-%m-%d')\n","\n","# Market data\n","stock_data = fetch_stock_data(ticker, start_date, end_date, interval='5m')\n","if not stock_data.empty:\n","    stock_data = add_technical_indicators(stock_data)\n","    stock_data = generate_target(stock_data)\n","    X_market, y_market = prepare_data(stock_data)\n","    market_models = train_cascade(X_market, y_market)\n","    unpruned_market, market_accuracies, market_correct, market_incorrect = cascading_predict(market_models, X_market, y_market)\n","    market_accuracy = accuracy_score([x[2] for x in unpruned_market], [np.argmax(x[0]) for x in unpruned_market])\n","    print(f\"Market Data Overall Accuracy: {market_accuracy:.4f}\")\n","    print(\"Market Data Level-wise Accuracies:\", market_accuracies)\n","    print(\"Market Data Level-wise Correct Predictions:\", market_correct)\n","    print(\"Market Data Level-wise Incorrect Predictions:\", market_incorrect)\n","    plot_level_performance(market_accuracies, market_correct, market_incorrect, title=\"Market Data Cascade Performance\")\n","else:\n","    print(\"Market data unavailable.\")\n","\n","# Synthetic data\n","X_synthetic, y_synthetic = generate_synthetic_data()\n","synthetic_models = train_cascade(X_synthetic, y_synthetic)\n","unpruned_synthetic, synthetic_accuracies, synthetic_correct, synthetic_incorrect = cascading_predict(synthetic_models, X_synthetic, y_synthetic)\n","synthetic_accuracy = accuracy_score([x[2] for x in unpruned_synthetic], [np.argmax(x[0]) for x in unpruned_synthetic])\n","print(f\"Synthetic Data Overall Accuracy: {synthetic_accuracy:.4f}\")\n","print(\"Synthetic Data Level-wise Accuracies:\", synthetic_accuracies)\n","print(\"Synthetic Data Level-wise Correct Predictions:\", synthetic_correct)\n","print(\"Synthetic Data Level-wise Incorrect Predictions:\", synthetic_incorrect)\n","plot_level_performance(synthetic_accuracies, synthetic_correct, synthetic_incorrect, title=\"Synthetic Data Cascade Performance\")\n"],"metadata":{"id":"GI6KNOx51r8U","executionInfo":{"status":"error","timestamp":1733071368322,"user_tz":-330,"elapsed":7519,"user":{"displayName":"Damanjit Singh","userId":"08687351702135121050"}},"colab":{"base_uri":"https://localhost:8080/","height":469},"outputId":"42a456a2-5173-4a7d-b8de-098a67b9010f"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["\r[*********************100%***********************]  1 of 1 completed\n"]},{"output_type":"error","ename":"ValueError","evalue":"Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-6073f47c3946>\u001b[0m in \u001b[0;36m<cell line: 129>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0mX_market\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_market\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstock_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0mmarket_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_cascade\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_market\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_market\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0munpruned_market\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarket_accuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarket_correct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarket_incorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcascading_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarket_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_market\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_market\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0mmarket_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munpruned_market\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munpruned_market\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Market Data Overall Accuracy: {market_accuracy:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-6073f47c3946>\u001b[0m in \u001b[0;36mcascading_predict\u001b[0;34m(models, X, y, max_impurity)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mcorrect_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mincorrect_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \"\"\"\n\u001b[1;32m   1246\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1247\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pass_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_forward_pass_fast\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \"\"\"\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;31m# Initialize first layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1048\u001b[0m                         \u001b[0;34m\"if it contains a single sample.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m                     )\n\u001b[0;32m-> 1050\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"kind\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m\"USV\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."]}]},{"cell_type":"code","source":["import joblib\n","import os\n","\n","# Save cascade models to a directory\n","def save_cascade_models(models, directory=\"cascade_models\"):\n","    if not os.path.exists(directory):\n","        os.makedirs(directory)\n","    for i, model in enumerate(models):\n","        filename = os.path.join(directory, f\"model_level_{i+1}.joblib\")\n","        joblib.dump(model, filename)\n","    print(f\"Models saved to {directory}\")\n","\n","# Example: Save trained models\n","save_cascade_models(market_models, directory=\"/content/drive/MyDrive/Cascading_model\")"],"metadata":{"id":"-DCudU311f_a","executionInfo":{"status":"aborted","timestamp":1733071368335,"user_tz":-330,"elapsed":46,"user":{"displayName":"Damanjit Singh","userId":"08687351702135121050"}}},"execution_count":null,"outputs":[]}]}